/**
 * Client-side model registry.
 * This mirrors the server-side configuration for the UI.
 */
import type { AIProvider, ModelInfo, ProviderInfo } from '~/types/model';

export const MODELS: Record<AIProvider, ModelInfo[]> = {
  anthropic: [
    {
      id: 'claude-sonnet-4-5-20250929',
      name: 'Claude Sonnet 4.5',
      description: 'Best overall coding model with 30+ hour autonomy',
      provider: 'anthropic',
      maxTokens: 8192,
      contextWindow: 200000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 3, output: 15 },
      isDefault: true,
    },
    {
      id: 'claude-sonnet-4-20250514',
      name: 'Claude Sonnet 4',
      description: 'Previous generation, highly capable',
      provider: 'anthropic',
      maxTokens: 8192,
      contextWindow: 200000,
      capabilities: { vision: true, tools: true, coding: true },
      pricing: { input: 3, output: 15 },
    },
    {
      id: 'claude-3-5-sonnet-20240620',
      name: 'Claude 3.5 Sonnet (Legacy)',
      description: 'Legacy model kept for backward compatibility',
      provider: 'anthropic',
      maxTokens: 8192,
      contextWindow: 200000,
      capabilities: { vision: true, tools: true, coding: true },
      pricing: { input: 3, output: 15 },
    },
  ],
  openai: [
    {
      id: 'gpt-5',
      name: 'GPT-5',
      description: 'Flagship general-intelligence model with persistent chain-of-thought and world-class coding skills',
      provider: 'openai',
      maxTokens: 16384,
      contextWindow: 256000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 4.8, output: 14.5 },
      isDefault: true,
    },
    {
      id: 'gpt-5-mini',
      name: 'GPT-5 Mini',
      description: 'High-accuracy GPT-5 tier tuned for fast iteration and agent loops',
      provider: 'openai',
      maxTokens: 12288,
      contextWindow: 128000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true, fast: true },
      pricing: { input: 2.2, output: 6.6 },
    },
    {
      id: 'gpt-4.1',
      name: 'GPT-4.1',
      description: '2025 refresh optimized for software engineering and compliance workloads',
      provider: 'openai',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { vision: true, tools: true, coding: true },
      pricing: { input: 2.6, output: 9.5 },
    },
    {
      id: 'o3',
      name: 'OpenAI o3',
      description: 'Reasoning-first model excelling at proofs, strategy, and complex debugging',
      provider: 'openai',
      maxTokens: 100000,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 9.5, output: 36 },
      isReasoningModel: true,
    },
    {
      id: 'o4-mini',
      name: 'OpenAI o4-mini',
      description: 'Lightweight reasoning model for orchestrating multi-agent systems at low cost',
      provider: 'openai',
      maxTokens: 65536,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true, fast: true },
      pricing: { input: 1, output: 4 },
      isReasoningModel: true,
    },
    {
      id: 'gpt-4o',
      name: 'GPT-4o',
      description: 'Multimodal GPT-4o (Nov 2025) with state-of-the-art audio and vision grounding',
      provider: 'openai',
      maxTokens: 16384,
      contextWindow: 128000,
      capabilities: { vision: true, tools: true, coding: true },
      pricing: { input: 2.3, output: 9.2 },
    },
  ],
  google: [
    {
      id: 'gemini-2.5-pro',
      name: 'Gemini 2.5 Pro',
      description:
        'Latest Gemini 2.5 Pro model with 4M context window, optimized for complex reasoning and coding tasks',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 4000000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 4.2, output: 12.6 },
      isDefault: true,
    },
    {
      id: 'gemini-2.0-pro',
      name: 'Gemini 2.0 Pro',
      description: 'Next-generation Gemini 2.0 Pro with 3M context window and enhanced multimodal capabilities',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 3000000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 3.8, output: 11.4 },
    },
    {
      id: 'gemini-2.0-flash',
      name: 'Gemini 2.0 Flash',
      description: 'Fast, multimodal model with 2M context window, optimized for real-time coding and iteration',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 2000000,
      capabilities: { vision: true, tools: true, coding: true, fast: true },
      pricing: { input: 0.095, output: 0.38 },
    },
    {
      id: 'gemini-2.0-ultra',
      name: 'Gemini 2.0 Ultra',
      description: 'Premium tier model with 5M context window for the most complex tasks and advanced reasoning',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 5000000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 6.5, output: 19.5 },
    },
    {
      id: 'codegemma-7b',
      name: 'CodeGemma 7B',
      description: 'Specialized coding model optimized for code generation, debugging, and software development tasks',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.18, output: 0.18 },
    },
    {
      id: 'gemma-3-27b-it',
      name: 'Gemma 3 27B',
      description: 'Latest Gemma 3 model with advanced reasoning, coding capabilities, and improved performance',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 0.95, output: 0.95 },
    },
    {
      id: 'gemma-3-7b-it',
      name: 'Gemma 3 7B',
      description: 'Efficient Gemma 3 model optimized for fast response, cost-effectiveness, and general coding tasks',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.28, output: 0.28 },
    },
    {
      id: 'gemini-1.5-pro-latest',
      name: 'Gemini 1.5 Pro (Legacy)',
      description: 'Previous generation Gemini 1.5 Pro model with 2M context window, kept for backward compatibility',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 2000000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 3.5, output: 10.5 },
    },
    {
      id: 'gemini-1.5-flash-latest',
      name: 'Gemini 1.5 Flash (Legacy)',
      description: 'Previous generation fast model with 1M context window, kept for backward compatibility',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 1000000,
      capabilities: { vision: true, tools: true, coding: true, fast: true },
      pricing: { input: 0.075, output: 0.3 },
    },
  ],
  deepseek: [
    {
      id: 'deepseek-chat',
      name: 'DeepSeek Chat V3.2-Exp',
      description: 'Latest DeepSeek-V3.2-Exp model with 128K context and enhanced reasoning',
      provider: 'deepseek',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 0.028, output: 0.042, cachedInput: 0.014 },
      isDefault: true,
    },
    {
      id: 'deepseek-reasoner',
      name: 'DeepSeek Reasoner V3.2-Exp',
      description: 'Latest DeepSeek-V3.2-Exp reasoning model with transparent chain-of-thought and 64K output',
      provider: 'deepseek',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 0.028, output: 0.042, cachedInput: 0.014 },
      isReasoningModel: true,
    },
  ],
  xai: [
    {
      id: 'grok-4-fast-reasoning',
      name: 'Grok 4 Fast Reasoning',
      description: 'Low-latency Grok 4 tier with upgraded tool use and 4x cheaper thinking bursts',
      provider: 'xai',
      maxTokens: 8192,
      contextWindow: 131072,
      capabilities: { tools: true, reasoning: true, coding: true, fast: true },
      pricing: { input: 0.35, output: 1.8, cachedInput: 0.035 },
      isDefault: true,
      isReasoningModel: true,
    },
    {
      id: 'grok-4',
      name: 'Grok 4',
      description: 'Full-strength Grok model with integrated real-time search and GPU-native tools',
      provider: 'xai',
      maxTokens: 8192,
      contextWindow: 131072,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 4.5, output: 13.5 },
    },
    {
      id: 'grok-code-fast-1-5',
      name: 'Grok Code Fast 1.5',
      description: 'Iterative coding specialist ideal for refactors, pull-request reviews, and agent work',
      provider: 'xai',
      maxTokens: 8192,
      contextWindow: 131072,
      capabilities: { tools: true, reasoning: true, coding: true, fast: true },
      pricing: { input: 0.22, output: 1.6, cachedInput: 0.022 },
    },
  ],
  mistral: [
    {
      id: 'codestral-25.10',
      name: 'Codestral 25.10',
      description: 'Latest Codestral with 300K context and compiler-aware reasoning',
      provider: 'mistral',
      maxTokens: 8192,
      contextWindow: 300000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.28, output: 0.82 },
      isDefault: true,
    },
    {
      id: 'mistral-large-2',
      name: 'Mistral Large 2',
      description: 'Second-generation large model optimized for multilingual engineering',
      provider: 'mistral',
      maxTokens: 8192,
      contextWindow: 160000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 1.9, output: 5.4 },
    },
    {
      id: 'mistral-small-3',
      name: 'Mistral Small 3',
      description: 'Ultra-fast assistant built for microservices, CLI agents, and automation',
      provider: 'mistral',
      maxTokens: 8192,
      contextWindow: 48000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.18, output: 0.5 },
    },
  ],
  zai: [
    {
      id: 'glm-4.6-ultra',
      name: 'GLM-4.6 Ultra',
      description: 'Premium GLM tier with upgraded long-context reasoning and math accuracy.',
      provider: 'zai',
      maxTokens: 8192,
      contextWindow: 220000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 1.2, output: 2.4 },
      isDefault: true,
    },
    {
      id: 'glm-4.6',
      name: 'GLM-4.6',
      description: 'Balanced GLM flagship for enterprise coding assistants and RAG systems.',
      provider: 'zai',
      maxTokens: 8192,
      contextWindow: 200000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 1.0, output: 2.0 },
    },
    {
      id: 'glm-4.5-flash',
      name: 'GLM-4.5 Flash',
      description: 'Flash tier tuned for sub-second completions and rapid auto-complete.',
      provider: 'zai',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.35, output: 0.7 },
    },
    {
      id: 'glm-4-plus',
      name: 'GLM-4-Plus',
      description: 'Enhanced GLM variant with improved multilingual reasoning.',
      provider: 'zai',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 0.5, output: 1.0 },
    },
    {
      id: 'glm-4-air',
      name: 'GLM-4-Air',
      description: 'Lightweight GLM model for devices and high-concurrency deployments.',
      provider: 'zai',
      maxTokens: 4096,
      contextWindow: 32000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.18, output: 0.38 },
    },
  ],

  groq: [
    {
      id: 'llama-3.3-70b-versatile',
      name: 'Llama 3.3 70B',
      description: 'Most capable Llama model with fast inference',
      provider: 'groq',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.59, output: 0.79 },
      isDefault: true,
    },
    {
      id: 'llama-3.1-8b-instant',
      name: 'Llama 3.1 8B Instant',
      description: 'Blazing fast 8B model for quick responses',
      provider: 'groq',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.05, output: 0.08 },
    },
    {
      id: 'mixtral-8x22b',
      name: 'Mixtral 8x22B',
      description: 'Newest Groq deployment of Mixtral with larger experts for structured reasoning',
      provider: 'groq',
      maxTokens: 8192,
      contextWindow: 32768,
      capabilities: { tools: true, coding: true, reasoning: true },
      pricing: { input: 0.33, output: 0.33 },
    },
    {
      id: 'gemma-3-12b',
      name: 'Gemma 3 12B',
      description: 'Gemma 3 upgrade optimized for instructions, spreadsheets, and IAM policies',
      provider: 'groq',
      maxTokens: 8192,
      contextWindow: 8192,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.18, output: 0.18 },
    },
  ],
};

export const PROVIDERS: ProviderInfo[] = [
  { id: 'anthropic', name: 'Anthropic', models: MODELS.anthropic },
  { id: 'openai', name: 'OpenAI', models: MODELS.openai },
  { id: 'google', name: 'Google', models: MODELS.google },
  { id: 'deepseek', name: 'DeepSeek', models: MODELS.deepseek },
  { id: 'xai', name: 'xAI', models: MODELS.xai },
  { id: 'mistral', name: 'Mistral', models: MODELS.mistral },
  { id: 'zai', name: 'ZAI (GLM)', models: MODELS.zai },
  { id: 'groq', name: 'Groq', models: MODELS.groq },
];

export function getAllModels(): ModelInfo[] {
  return Object.values(MODELS).flat();
}

export function getProviderModels(provider: AIProvider): ModelInfo[] {
  return MODELS[provider] || [];
}

export function getModel(provider: AIProvider, modelId: string): ModelInfo | undefined {
  return MODELS[provider]?.find((m) => m.id === modelId);
}

export function getDefaultModel(provider: AIProvider): ModelInfo | undefined {
  const models = MODELS[provider] || [];
  return models.find((m) => m.isDefault) || models[0];
}
