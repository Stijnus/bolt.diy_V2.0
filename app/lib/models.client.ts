/**
 * Client-side model registry.
 * This mirrors the server-side configuration for the UI.
 */
import type { AIProvider, ModelInfo, ProviderInfo } from '~/types/model';

export const MODELS: Record<AIProvider, ModelInfo[]> = {
  anthropic: [
    {
      id: 'claude-sonnet-4-5-20250929',
      name: 'Claude Sonnet 4.5',
      description: 'Best overall coding model with 30+ hour autonomy',
      provider: 'anthropic',
      maxTokens: 8192,
      contextWindow: 200000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 3, output: 15 },
      isDefault: true,
    },
    {
      id: 'claude-sonnet-4-20250514',
      name: 'Claude Sonnet 4',
      description: 'Previous generation, highly capable',
      provider: 'anthropic',
      maxTokens: 8192,
      contextWindow: 200000,
      capabilities: { vision: true, tools: true, coding: true },
      pricing: { input: 3, output: 15 },
    },
    {
      id: 'claude-3-5-sonnet-20240620',
      name: 'Claude 3.5 Sonnet (Legacy)',
      description: 'Legacy model kept for backward compatibility',
      provider: 'anthropic',
      maxTokens: 8192,
      contextWindow: 200000,
      capabilities: { vision: true, tools: true, coding: true },
      pricing: { input: 3, output: 15 },
    },
  ],
  openai: [
    {
      id: 'gpt-5',
      name: 'GPT-5',
      description: 'Flagship general-intelligence model with persistent chain-of-thought and world-class coding skills',
      provider: 'openai',
      maxTokens: 16384,
      contextWindow: 256000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 4.8, output: 14.5 },
      isDefault: true,
    },
    {
      id: 'gpt-5-mini',
      name: 'GPT-5 Mini',
      description: 'High-accuracy GPT-5 tier tuned for fast iteration and agent loops',
      provider: 'openai',
      maxTokens: 12288,
      contextWindow: 128000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true, fast: true },
      pricing: { input: 2.2, output: 6.6 },
    },
    {
      id: 'gpt-4.1',
      name: 'GPT-4.1',
      description: '2025 refresh optimized for software engineering and compliance workloads',
      provider: 'openai',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { vision: true, tools: true, coding: true },
      pricing: { input: 2.6, output: 9.5 },
    },
    {
      id: 'o3',
      name: 'OpenAI o3',
      description: 'Reasoning-first model excelling at proofs, strategy, and complex debugging',
      provider: 'openai',
      maxTokens: 100000,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 9.5, output: 36 },
      isReasoningModel: true,
    },
    {
      id: 'o4-mini',
      name: 'OpenAI o4-mini',
      description: 'Lightweight reasoning model for orchestrating multi-agent systems at low cost',
      provider: 'openai',
      maxTokens: 65536,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true, fast: true },
      pricing: { input: 1, output: 4 },
      isReasoningModel: true,
    },
    {
      id: 'gpt-4o',
      name: 'GPT-4o',
      description: 'Multimodal GPT-4o (Nov 2025) with state-of-the-art audio and vision grounding',
      provider: 'openai',
      maxTokens: 16384,
      contextWindow: 128000,
      capabilities: { vision: true, tools: true, coding: true },
      pricing: { input: 2.3, output: 9.2 },
    },
  ],
  google: [
    {
      id: 'gemini-2.5-ultra',
      name: 'Gemini 2.5 Ultra',
      description: 'Enterprise flagship with 2M context, best-in-class web and Android knowledge',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 2000000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 3, output: 12 },
      isDefault: true,
    },
    {
      id: 'gemini-2.5-pro',
      name: 'Gemini 2.5 Pro',
      description: 'Balanced model for production-grade coding and architectural planning',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 1000000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 2.2, output: 8.8 },
    },
    {
      id: 'gemini-2.5-flash',
      name: 'Gemini 2.5 Flash',
      description: 'Latency-optimized tier with full multimodal support and cached contexts',
      provider: 'google',
      maxTokens: 8192,
      contextWindow: 1000000,
      capabilities: { vision: true, tools: true, coding: true, fast: true },
      pricing: { input: 0.12, output: 0.45 },
    },
  ],
  deepseek: [
    {
      id: 'deepseek-chat',
      name: 'DeepSeek Chat V3.2-Exp',
      description: 'Latest DeepSeek-V3.2-Exp model with 128K context and enhanced reasoning',
      provider: 'deepseek',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 0.028, output: 0.042, cachedInput: 0.014 },
      isDefault: true,
    },
    {
      id: 'deepseek-reasoner',
      name: 'DeepSeek Reasoner V3.2-Exp',
      description: 'Latest DeepSeek-V3.2-Exp reasoning model with transparent chain-of-thought and 64K output',
      provider: 'deepseek',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 0.028, output: 0.042, cachedInput: 0.014 },
      isReasoningModel: true,
    },
  ],
  xai: [
    {
      id: 'grok-4-fast-reasoning',
      name: 'Grok 4 Fast Reasoning',
      description: 'Low-latency Grok 4 tier with upgraded tool use and 4x cheaper thinking bursts',
      provider: 'xai',
      maxTokens: 8192,
      contextWindow: 131072,
      capabilities: { tools: true, reasoning: true, coding: true, fast: true },
      pricing: { input: 0.35, output: 1.8, cachedInput: 0.035 },
      isDefault: true,
      isReasoningModel: true,
    },
    {
      id: 'grok-4',
      name: 'Grok 4',
      description: 'Full-strength Grok model with integrated real-time search and GPU-native tools',
      provider: 'xai',
      maxTokens: 8192,
      contextWindow: 131072,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 4.5, output: 13.5 },
    },
    {
      id: 'grok-code-fast-1-5',
      name: 'Grok Code Fast 1.5',
      description: 'Iterative coding specialist ideal for refactors, pull-request reviews, and agent work',
      provider: 'xai',
      maxTokens: 8192,
      contextWindow: 131072,
      capabilities: { tools: true, reasoning: true, coding: true, fast: true },
      pricing: { input: 0.22, output: 1.6, cachedInput: 0.022 },
    },
  ],
  mistral: [
    {
      id: 'codestral-25.10',
      name: 'Codestral 25.10',
      description: 'Latest Codestral with 300K context and compiler-aware reasoning',
      provider: 'mistral',
      maxTokens: 8192,
      contextWindow: 300000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.28, output: 0.82 },
      isDefault: true,
    },
    {
      id: 'mistral-large-2',
      name: 'Mistral Large 2',
      description: 'Second-generation large model optimized for multilingual engineering',
      provider: 'mistral',
      maxTokens: 8192,
      contextWindow: 160000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 1.9, output: 5.4 },
    },
    {
      id: 'mistral-small-3',
      name: 'Mistral Small 3',
      description: 'Ultra-fast assistant built for microservices, CLI agents, and automation',
      provider: 'mistral',
      maxTokens: 8192,
      contextWindow: 48000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.18, output: 0.5 },
    },
  ],
  zai: [
    {
      id: 'glm-4.6-ultra',
      name: 'GLM-4.6 Ultra',
      description: 'Premium GLM tier with upgraded long-context reasoning and math accuracy.',
      provider: 'zai',
      maxTokens: 8192,
      contextWindow: 220000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 1.2, output: 2.4 },
      isDefault: true,
    },
    {
      id: 'glm-4.6',
      name: 'GLM-4.6',
      description: 'Balanced GLM flagship for enterprise coding assistants and RAG systems.',
      provider: 'zai',
      maxTokens: 8192,
      contextWindow: 200000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 1.0, output: 2.0 },
    },
    {
      id: 'glm-4.5-flash',
      name: 'GLM-4.5 Flash',
      description: 'Flash tier tuned for sub-second completions and rapid auto-complete.',
      provider: 'zai',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.35, output: 0.7 },
    },
    {
      id: 'glm-4-plus',
      name: 'GLM-4-Plus',
      description: 'Enhanced GLM variant with improved multilingual reasoning.',
      provider: 'zai',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 0.5, output: 1.0 },
    },
    {
      id: 'glm-4-air',
      name: 'GLM-4-Air',
      description: 'Lightweight GLM model for devices and high-concurrency deployments.',
      provider: 'zai',
      maxTokens: 4096,
      contextWindow: 32000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.18, output: 0.38 },
    },
  ],

  // Newly added providers (static defaults; will be enhanced by dynamic listing)
  openrouter: [
    {
      id: 'openrouter/auto',
      name: 'OpenRouter Auto',
      description: 'Router that selects an appropriate upstream model automatically.',
      provider: 'openrouter',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true },
      pricing: { input: 0, output: 0 },
      isDefault: true,
    },
  ],
  qwen: [
    {
      id: 'qwen2.5-max',
      name: 'Qwen2.5 Max',
      description: 'Newest Alibaba flagship with dual-language reasoning and 1.5M context in streaming mode.',
      provider: 'qwen',
      maxTokens: 8192,
      contextWindow: 1536000,
      capabilities: { vision: true, tools: true, reasoning: true, coding: true },
      pricing: { input: 1.4, output: 5.6 },
      isDefault: true,
    },
    {
      id: 'qwen2.5-coder-turbo',
      name: 'Qwen2.5 Coder Turbo',
      description: 'High-throughput coder tuned for TypeScript, Java, and Python repositories.',
      provider: 'qwen',
      maxTokens: 8192,
      contextWindow: 256000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.62, output: 2.3 },
    },
    {
      id: 'qwen2.5-mini',
      name: 'Qwen2.5 Mini',
      description: 'Cost-effective assistant for agents and background jobs.',
      provider: 'qwen',
      maxTokens: 4096,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.12, output: 0.38 },
    },
  ],
  moonshot: [
    {
      id: 'moonshot-k1.5-pro',
      name: 'Moonshot K1.5 Pro',
      description: 'Premium Kimi model focused on product design, UX copy, and TypeScript.',
      provider: 'moonshot',
      maxTokens: 8192,
      contextWindow: 160000,
      capabilities: { tools: true, coding: true, reasoning: true },
      pricing: { input: 0.72, output: 2.8 },
      isDefault: true,
    },
    {
      id: 'moonshot-k1-flash',
      name: 'Moonshot K1 Flash',
      description: 'Flash tier for rapid iteration with deterministic summaries and planning.',
      provider: 'moonshot',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.28, output: 1.1 },
    },
  ],
  cerebras: [
    {
      id: 'llama3.3-70b',
      name: 'Llama 3.3 70B (Cerebras)',
      description: 'Latest Llama 3.3 hosted on Cerebras accelerators with blazing inference speeds.',
      provider: 'cerebras',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.58, output: 0.58 },
      isDefault: true,
    },
    {
      id: 'gemma-3-12b',
      name: 'Gemma 3 12B (Cerebras)',
      description: 'Google Gemma 3 mid-tier optimized for UI copy, docs, and lightweight agents.',
      provider: 'cerebras',
      maxTokens: 8192,
      contextWindow: 64000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.22, output: 0.22 },
    },
    {
      id: 'mixtral-8x7b-cerebras',
      name: 'Mixtral 8x7B (Cerebras)',
      description: 'Hosted Mixtral with accelerator-friendly MoE routing for parallel workloads.',
      provider: 'cerebras',
      maxTokens: 8192,
      contextWindow: 32768,
      capabilities: { tools: true, coding: true },
      pricing: { input: 0.34, output: 0.34 },
    },
  ],
  groq: [
    {
      id: 'llama-3.3-70b-versatile',
      name: 'Llama 3.3 70B',
      description: 'Most capable Llama model with fast inference',
      provider: 'groq',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.59, output: 0.79 },
      isDefault: true,
    },
    {
      id: 'llama-3.1-8b-instant',
      name: 'Llama 3.1 8B Instant',
      description: 'Blazing fast 8B model for quick responses',
      provider: 'groq',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.05, output: 0.08 },
    },
    {
      id: 'mixtral-8x22b',
      name: 'Mixtral 8x22B',
      description: 'Newest Groq deployment of Mixtral with larger experts for structured reasoning',
      provider: 'groq',
      maxTokens: 8192,
      contextWindow: 32768,
      capabilities: { tools: true, coding: true, reasoning: true },
      pricing: { input: 0.33, output: 0.33 },
    },
    {
      id: 'gemma-3-12b',
      name: 'Gemma 3 12B',
      description: 'Gemma 3 upgrade optimized for instructions, spreadsheets, and IAM policies',
      provider: 'groq',
      maxTokens: 8192,
      contextWindow: 8192,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.18, output: 0.18 },
    },
  ],
  together: [
    {
      id: 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo',
      name: 'Llama 3.1 70B Turbo',
      description: 'Fast inference for Llama 3.1 70B',
      provider: 'together',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.88, output: 0.88 },
      isDefault: true,
    },
    {
      id: 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo',
      name: 'Llama 3.1 8B Turbo',
      description: 'Ultra-fast 8B model for quick tasks',
      provider: 'together',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.18, output: 0.18 },
    },
    {
      id: 'mistralai/Mixtral-8x7B-Instruct-v0.1',
      name: 'Mixtral 8x7B',
      description: 'Mixture of experts model from Mistral',
      provider: 'together',
      maxTokens: 8192,
      contextWindow: 32768,
      capabilities: { tools: true, coding: true },
      pricing: { input: 0.6, output: 0.6 },
    },
    {
      id: 'Qwen/Qwen2.5-72B-Instruct-Turbo',
      name: 'Qwen 2.5 72B Turbo',
      description: 'Alibaba Qwen model optimized for coding',
      provider: 'together',
      maxTokens: 8192,
      contextWindow: 32768,
      capabilities: { tools: true, coding: true },
      pricing: { input: 1.2, output: 1.2 },
    },
    {
      id: 'deepseek-ai/deepseek-coder-33b-instruct',
      name: 'DeepSeek Coder 33B',
      description: 'Specialized coding model',
      provider: 'together',
      maxTokens: 8192,
      contextWindow: 16384,
      capabilities: { tools: true, coding: true },
      pricing: { input: 0.8, output: 0.8 },
    },
  ],
  perplexity: [
    {
      id: 'sonar-pro-2-online',
      name: 'Sonar Pro 2 (Online)',
      description: 'Latest Sonar with live web search, citations, and improved RAG speed.',
      provider: 'perplexity',
      maxTokens: 8192,
      contextWindow: 160000,
      capabilities: { tools: true, coding: true, reasoning: true },
      pricing: { input: 1.1, output: 1.1 },
      isDefault: true,
    },
    {
      id: 'sonar-lite-2-online',
      name: 'Sonar Lite 2 (Online)',
      description: 'Lightweight web-enabled assistant ideal for quick fact checks and scaffolding.',
      provider: 'perplexity',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.22, output: 0.22 },
    },
    {
      id: 'llama-3.1-405b-offline',
      name: 'Llama 3.1 405B (Offline)',
      description: 'Largest offline option for high-accuracy reasoning without external calls.',
      provider: 'perplexity',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, reasoning: true },
      pricing: { input: 1.6, output: 1.6 },
    },
  ],
  cohere: [
    {
      id: 'command-r-plus',
      name: 'Command R+',
      description: 'Most capable model for complex tasks and RAG',
      provider: 'cohere',
      maxTokens: 4096,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, reasoning: true },
      pricing: { input: 3, output: 15 },
      isDefault: true,
    },
    {
      id: 'command-r-long',
      name: 'Command R Long',
      description: 'Extended-context Command variant with 1M token intake for document workflows',
      provider: 'cohere',
      maxTokens: 4096,
      contextWindow: 1000000,
      capabilities: { tools: true, coding: true, reasoning: true },
      pricing: { input: 1.8, output: 6.2 },
    },
    {
      id: 'command-r',
      name: 'Command R',
      description: 'Balanced model for general tasks',
      provider: 'cohere',
      maxTokens: 4096,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true },
      pricing: { input: 0.5, output: 1.5 },
    },
    {
      id: 'command-light',
      name: 'Command Light',
      description: 'Ultra-fast lightweight model',
      provider: 'cohere',
      maxTokens: 4096,
      contextWindow: 4096,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.3, output: 0.6 },
    },
    {
      id: 'aya-23',
      name: 'Aya 23',
      description: 'Open Aya release from Cohere For AI for multilingual experimentation',
      provider: 'cohere',
      maxTokens: 4096,
      contextWindow: 200000,
      capabilities: { tools: true, coding: true, reasoning: true },
      pricing: { input: 0.0, output: 0.0 },
    },
  ],
  fireworks: [
    {
      id: 'accounts/fireworks/models/llama-v3p2-90b-instruct',
      name: 'Llama 3.2 90B',
      description: 'Fireworks-hosted Llama with 90B active params and near-cost parity to 70B.',
      provider: 'fireworks',
      maxTokens: 8192,
      contextWindow: 160000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.88, output: 0.88 },
      isDefault: true,
    },
    {
      id: 'accounts/fireworks/models/qwen2p5-coder-72b',
      name: 'Qwen2.5 Coder 72B',
      description: 'Alibaba coder giant optimized for Fireworks inference stack.',
      provider: 'fireworks',
      maxTokens: 8192,
      contextWindow: 128000,
      capabilities: { tools: true, coding: true, reasoning: true },
      pricing: { input: 0.95, output: 0.95 },
    },
    {
      id: 'accounts/fireworks/models/deepseek-r1',
      name: 'DeepSeek R1 (Fireworks)',
      description: 'Hosted DeepSeek reasoning model with managed tool-calling and caching.',
      provider: 'fireworks',
      maxTokens: 8192,
      contextWindow: 64000,
      capabilities: { tools: true, reasoning: true, coding: true },
      pricing: { input: 0.92, output: 0.92 },
      isReasoningModel: true,
    },
    {
      id: 'accounts/fireworks/models/mamba-3-24b',
      name: 'Mamba 3 24B',
      description: 'State-space model ideal for streaming data, logs, and telemetry summaries.',
      provider: 'fireworks',
      maxTokens: 8192,
      contextWindow: 200000,
      capabilities: { tools: true, coding: true, fast: true },
      pricing: { input: 0.42, output: 0.42 },
    },
    {
      id: 'accounts/fireworks/models/yi-large',
      name: 'Yi Large',
      description: '01.AI flagship model',
      provider: 'fireworks',
      maxTokens: 8192,
      contextWindow: 32768,
      capabilities: { tools: true, coding: true },
      pricing: { input: 3, output: 3 },
    },
  ],
};

export const PROVIDERS: ProviderInfo[] = [
  { id: 'anthropic', name: 'Anthropic', models: MODELS.anthropic },
  { id: 'openai', name: 'OpenAI', models: MODELS.openai },
  { id: 'google', name: 'Google', models: MODELS.google },
  { id: 'deepseek', name: 'DeepSeek', models: MODELS.deepseek },
  { id: 'xai', name: 'xAI', models: MODELS.xai },
  { id: 'mistral', name: 'Mistral', models: MODELS.mistral },
  { id: 'zai', name: 'ZAI (GLM)', models: MODELS.zai },
  { id: 'openrouter', name: 'OpenRouter', models: MODELS.openrouter },
  { id: 'qwen', name: 'Qwen (DashScope)', models: MODELS.qwen },
  { id: 'moonshot', name: 'Moonshot (Kimi)', models: MODELS.moonshot },
  { id: 'cerebras', name: 'Cerebras', models: MODELS.cerebras },
  { id: 'groq', name: 'Groq', models: MODELS.groq },
  { id: 'together', name: 'Together AI', models: MODELS.together },
  { id: 'perplexity', name: 'Perplexity AI', models: MODELS.perplexity },
  { id: 'cohere', name: 'Cohere', models: MODELS.cohere },
  { id: 'fireworks', name: 'Fireworks AI', models: MODELS.fireworks },
];

export function getAllModels(): ModelInfo[] {
  return Object.values(MODELS).flat();
}

export function getProviderModels(provider: AIProvider): ModelInfo[] {
  return MODELS[provider] || [];
}

export function getModel(provider: AIProvider, modelId: string): ModelInfo | undefined {
  return MODELS[provider]?.find((m) => m.id === modelId);
}

export function getDefaultModel(provider: AIProvider): ModelInfo | undefined {
  const models = MODELS[provider] || [];
  return models.find((m) => m.isDefault) || models[0];
}
